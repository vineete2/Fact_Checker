{"headline": "Brainlike Computers, Learning From Experience", "body": "\nPALO ALTO, Calif. \u2014 Computers have entered the age when they are able to learn from their own mistakes, a development that is about to turn the digital world on its head.         \n\nThe first commercial version of the new kind of computer chip is scheduled to be released in 2014. Not only can it automate tasks that now require painstaking programming \u2014 for example, moving a robot\u2019s arm smoothly and efficiently \u2014 but it can also sidestep and even tolerate errors, potentially making the term \u201ccomputer crash\u201d obsolete.         \n\nThe new computing approach, already in use by some large technology companies, is based on the biological nervous system, specifically on how neurons react to stimuli and connect with other neurons to interpret information. It allows computers to absorb new information while carrying out a task, and adjust what they do based on the changing signals.         \n\nIn coming years, the approach will make possible a new generation of artificial intelligence systems that will perform some functions that humans do with ease: see, speak, listen, navigate, manipulate and control. That can hold enormous consequences for tasks like facial and speech recognition, navigation and planning, which are still in elementary stages and rely heavily on human programming.         \n\nDesigners say the computing style can clear the way for robots that can safely walk and drive in the physical world, though a thinking or conscious computer, a staple of science fiction, is still far off on the digital horizon.         \n\n\u201cWe\u2019re moving from engineering computing systems to something that has many of the characteristics of biological computing,\u201d said  \n, an astrophysicist who directs the  \n, one of many research centers devoted to developing these new kinds of computer circuits.         \n\nConventional computers are limited by what they have been programmed to do. Computer vision systems, for example, only \u201crecognize\u201d objects that can be identified by the statistics-oriented algorithms programmed into them. An algorithm is like a recipe, a set of step-by-step instructions to perform a calculation.         \n\nBut last year, Google researchers were able to get a machine-learning algorithm, known as a neural network, to perform an identification task without supervision. The network scanned a database of 10 million images, and in doing so trained itself to recognize cats.         \n\nIn June, the company  \n it had used those neural network techniques to develop a new search service to help customers find specific photos more accurately.         \n\nThe new approach, used in both hardware and software, is being driven by the explosion of scientific knowledge about the brain.  \n, a computer scientist who leads Stanford\u2019s  \n research program, said that is also its limitation, as scientists are far from fully understanding how brains function.         \n\n\u201cWe have no clue,\u201d he said. \u201cI\u2019m an engineer, and I build things. There are these highfalutin theories, but give me one that will let me build something.\u201d         \n\nUntil now, the design of computers was dictated by ideas originated by the mathematician  \n about 65 years ago. Microprocessors perform operations at lightning speed, following instructions programmed using long strings of 1s and 0s. They generally store that information separately in what is known, colloquially, as memory, either in the processor itself, in adjacent storage chips or in higher capacity magnetic disk drives.         \n\nThe data \u2014 for instance, temperatures for a climate model or letters for word processing \u2014 are shuttled in and out of the processor\u2019s short-term memory while the computer carries out the programmed action. The result is then moved to its main memory.         \n\nThe new processors consist of electronic components that can be connected by wires that mimic biological synapses. Because they are based on large groups of neuron-like elements, they are known as neuromorphic processors, a term credited to the California Institute of Technology physicist  \n, who pioneered the concept in the late 1980s.         \n\nThey are not \u201cprogrammed.\u201d Rather the connections between the circuits are \u201cweighted\u201d according to correlations in data that the processor has already \u201clearned.\u201d Those weights are then altered as data flows in to the chip, causing them to change their values and to \u201cspike.\u201d That generates a signal that travels to other components and, in reaction, changes the neural network, in essence programming the next actions much the same way that information alters human thoughts and actions.         \n\n\u201cInstead of bringing data to computation as we do today, we can now bring computation to data,\u201d said  \n  \n, an I.B.M. computer scientist who leads the company\u2019s cognitive computing research effort. \u201cSensors become the computer, and it opens up a new way to use computer chips that can be everywhere.\u201d         \n\nThe new computers, which are still based on silicon chips, will not replace today\u2019s computers, but will augment them, at least for now. Many computer designers see them as coprocessors, meaning they can work in tandem with other circuits that can be embedded in smartphones and in the giant centralized computers that make up the cloud. Modern computers already consist of a variety of coprocessors that perform specialized tasks, like producing graphics on your cellphone and converting visual, audio and other data for your laptop.         \n\nOne great advantage of the new approach is its ability to tolerate glitches. Traditional computers are precise, but they cannot work around the failure of even a single transistor. With the biological designs, the algorithms are ever changing, allowing the system to continuously adapt and work around failures to complete tasks.         \n\nTraditional computers are also remarkably energy inefficient, especially when compared to actual brains, which the new neurons are built to mimic.         \n\nI.B.M. announced last year that it had built a supercomputer simulation of the brain that encompassed roughly 10 billion neurons \u2014 more than 10 percent of a human brain. It ran about 1,500 times more slowly than an actual brain. Further, it required several megawatts of power, compared with just 20 watts of power used by the biological brain.         \n\nRunning the program, known as Compass, which attempts to simulate a brain, at the speed of a human brain would require a flow of electricity in a conventional computer that is equivalent to what is needed to power both San Francisco and New York, Dr. Modha said.         \n\nI.B.M. and Qualcomm, as well as the Stanford research team, have already designed neuromorphic processors, and Qualcomm has said that it is coming out in 2014 with a commercial version, which is expected to be used largely for further development. Moreover, many universities are now focused on this new style of computing. This fall the National Science Foundation financed the  \n, a new research center based at the Massachusetts Institute of Technology, with Harvard and Cornell.         \n\nThe largest class on campus this fall at Stanford was a graduate level machine-learning course covering both statistical and biological approaches, taught by the computer scientist  \n. More than 760 students enrolled. \u201cThat reflects the zeitgeist,\u201d said  \n, a computational neuroscientist at the Salk Institute, who pioneered early biologically inspired algorithms. \u201cEveryone knows there is something big happening, and they\u2019re trying find out what it is.\u201d        ", "url": "http://www.nytimes.com/2013/12/29/science/brainlike-computers-learning-from-experience.html", "date": "2013-12-28", "description": "The new computing approach is based on the biological nervous system, specifically on how neurons react to stimuli and connect with other neurons to interpret information."}