{"headline": "Algorithms Get a Human Hand in Steering Web", "body": "\nTrading stocks, targeting ads, steering political campaigns, arranging dates, besting people on \u201cJeopardy\u201d and even  \n: computer algorithms are doing all this work and more.         \n\nBut increasingly, behind the curtain there is a decidedly retro helper \u2014 a human being.         \n\nAlthough algorithms are growing ever more powerful, fast and precise, the computers themselves are literal-minded, and context and nuance often elude them. Capable as these machines are, they are not always up to deciphering the ambiguity of human language and the mystery of reasoning. Yet these days they are being asked to be more humanlike in what they figure out.         \n\n\u201cFor all their brilliance, computers can be thick as a brick,\u201d said Tom M. Mitchell, a computer scientist at Carnegie Mellon University.         \n\nAnd so, while programming experts still write the step-by-step instructions of computer code, additional people are needed to make more subtle contributions as the work the computers do has become more involved. People evaluate, edit or correct an algorithm\u2019s work. Or they assemble online databases of knowledge and check and verify them \u2014 creating, essentially, a crib sheet the computer can call on for a quick answer. Humans can interpret and tweak information in ways that are understandable to both computers and other humans.         \n\nQuestion-answering technologies like Apple\u2019s Siri and  \n\u2019s Watson rely particularly on the emerging machine-man collaboration. Algorithms alone are not enough.         \n\n \n uses a far-flung army of contract workers, whom it calls judges, to interpret the meaning and context of search terms that suddenly spike in frequency on the service.         \n\nFor example, when Mitt Romney talked of cutting government money for public broadcasting in a presidential debate last fall and mentioned Big Bird, messages with that phrase surged. Human judges recognized instantly that \u201cBig Bird,\u201d in that context and at that moment, was mainly a political comment, not a reference to \u201cSesame Street,\u201d and that politics-related messages should pop up when someone searched for \u201cBig Bird.\u201d People can understand such references more accurately and quickly than software can, and their judgments are fed immediately into Twitter\u2019s search algorithm.         \n\n\u201cHumans are core to this system,\u201d two Twitter engineers wrote in a blog post in January.         \n\nEven at  \n, where algorithms and engineers reign supreme in the company\u2019s business and culture, the human contribution to search results is increasing. Google uses human helpers in two ways. Several months ago, it began presenting summaries of information on the right side of a search page when a user typed in the name of a well-known person or place, like \u201cBarack Obama\u201d or \u201cNew York City.\u201d These summaries draw from databases of knowledge like Wikipedia, the C.I.A. World Factbook and Freebase, whose parent company, Metaweb,  \n in 2010. These databases are edited by humans.         \n\nWhen Google\u2019s algorithm detects a search term for which this distilled information is available, the search engine is trained to go fetch it rather than merely present links to Web pages.         \n\n\u201cThere has been a shift in our thinking,\u201d said Scott Huffman, an engineering director in charge of search quality at Google. \u201cA part of our resources are now more human curated.\u201d         \n\nOther human helpers, known as evaluators or raters, help Google develop tweaks to its search algorithm, a powerhouse of automation, fielding 100 billion queries a month. \u201cOur engineers evolve the algorithm, and humans help us see if a suggested change is really an improvement,\u201d Mr. Huffman said.         \n\nKatherine Young, 23, is a Google rater \u2014 a contract worker and a college student in Macon, Ga. She is shown an ambiguous search query like \u201cwhat does king hold,\u201d presented with two sets of Google search results and asked to rate their relevance, accuracy and quality. The current search result for that imprecise phrase starts with links to Web pages saying that kings typically hold ceremonial scepters, a reasonable inference.         \n\nHer judgments, Ms. Young said, are \u201cnot completely black and white; some of it is subjective.\u201d She added, \u201cYou try to put yourself in the shoes of the person who typed in the query.\u201d         \n\nI.B.M.\u2019s Watson, the powerful question-answering computer that defeated \u201cJeopardy\u201d champions two years ago, is in training these days to help doctors make diagnoses. But it, too, is turning to humans for help.         \n\nTo prepare for its role in assisting doctors, Watson is being fed medical texts, scientific papers and digital patient records stripped of personal identifying information. Instead of answering questions, however, Watson is asking them of clinicians at the Cleveland Clinic and medical school students. They are giving answers and correcting the computer\u2019s mistakes, using a \u201cTeach Watson\u201d feature.        ", "url": "http://www.nytimes.com/2013/03/11/technology/computer-algorithms-rely-increasingly-on-human-helpers.html", "date": "2013-03-10", "description": "Computer algorithms are capable of trading stocks, arranging dates and winning \u201cJeopardy.\u201d But increasingly, behind the curtain, there is a human helper."}